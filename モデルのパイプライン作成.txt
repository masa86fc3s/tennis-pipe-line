★モデルのパイプライン作成
大まかに、
1.s3にデータを保存する
2.データの前処理をする.pyファイルを作成する
3.データのモデルで学習させる.pyファイルを作成する
4.指標評価をする.pyファイルを作成する
5.1~4の.pyファイルをまとめたパイプライン.pyファイルを作成する。

パイプラインにするメリット
スケーラビリティが高い

＜使うパッケージ＞
import boto3

<使用ツール>
kaggle
aws : ec2,s3
vscode 

・MLopsを意識する
・今回は全てvscodeで簡潔させてみる。作成したファイル等全て(.ipynb、.py)...etc
・最初のモデル作成するときには、.ipファイル
　ある程度できてきたら.pyファイル


＜アサインされてから＞
ymlファイルの作成の時にlinuxのコマンドを使用する。

python : pandasがメイン、spark分散システム 
SQL : 基本的な構文

＜1.S3にモデルをアップロード＞
実際にはs3にログインして、直接ファイルをアップロードした方が早い気はする、、
コードでファイルを送るならこのコマンドを使用する。
aws s3 cp test.tsv s3://tennis-pipe-line/data/test.tsv --region ap-southeast-2
（最初に送りたいファイルの名前、//作ったバケットの名前/再生したいディレクトリの名前/送りたいファイルの名前 --regionはawsリージョンに記載されているコード）

